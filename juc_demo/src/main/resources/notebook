1.公平锁和非公平锁：(非公平锁吞吐量高)
公平锁：多个线程按照申请锁的顺序去获得锁，线程会直接进入队列去排队，永远都是队列的第一位才能得到锁。
    优点：所有的线程都能得到资源，不会饿死在队列中。
    缺点：吞吐量会下降很多，队列里面除了第一个线程，其他的线程都会阻塞，cpu唤醒阻塞线程的开销会很大。
非公平锁：多个线程去获取锁的时候，会直接去尝试获取，获取不到，再去进入等待队列，如果能获取到，就直接获取到锁。
    优点：可以减少CPU唤醒线程的开销，整体的吞吐效率会高点，CPU也不必取唤醒所有线程，会减少唤起线程的数量。
    缺点：你们可能也发现了，这样可能导致队列中间的线程一直获取不到锁或者长时间获取不到锁，导致饿死。
2.可重入锁(递归锁)：同一个线程可以进入任何一个他已经拥有锁的所同步着的代码块。（同一个线程，同一把锁）
    案例：ReentrantLock/Synchronized
    优点：可以避免死锁。
3.自旋锁：尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁(CAS)
    优点: 减少线程上下文切换的消耗
    缺点：循环会消耗CPU资源
4.独占锁(写)/共享锁(读)/互斥锁：
    独占锁：锁对象一次只能被一个线程持有(ReentrantLock/Synchronized)
    共享锁：锁对象一次能被多个线程持有
5.读写锁：
    写操作保证原子性，不可中断
    读-读 共享
    读-写 互斥
    写-写 互斥
6. ReentrantLock与Synchronized的区别：
6.1 Synchronized: JVM层面关键字
    monitorenter(底层通过monitor对象来完成，其实wait/notify等方法也依赖于monitor对象，只有在同步方法中才能调用wait/notify方法)
    monitorexit
    不需要手动释放，同步代码块执行完自动释放锁
    不可中断，除非抛异常或者正常运行完
    非公平锁
    随机唤醒一个线程，或者唤醒所有线程
6.2 ReentrantLock: 是具体的类，api层面的锁
    需要用户手动释放锁，否则会出现死锁情况
    可中断，可以用tryLock(long timeout, TimeUnit unit),或者lockInterruptibly()放代码块中，调用interrupt()方法可中断
    默认非公平锁，也可以设置为公平锁
    锁可以绑定多个condition条件变量，用来实现分组唤醒需要唤醒的线程们，可以精确唤醒
7.线程等待唤醒机制：
7.1 synchronized + wait + notify
    必须配合synchronized使用，否则 java.lang.IllegalMonitorStateException
    必须先调用wait()后调用notify()，否则会阻塞，无法唤醒
7.2 reentrantLock + await + signal
    必须配合reentrantLock使用，否则 java.lang.IllegalMonitorStateException
    必须先调用await()后调用signal()，否则会阻塞，无法唤醒
7.3 lockSupport + park + unpark
    LockSupport 是用来创建锁的和其他同步类的基本线程阻塞原语的工具类，底层调用Unsafe中的native方法
    LockSupport和每个使用他的线程都有一个许可证（permit）关联，默认是0，而且最多只有 1个许可证。
    调用一次unpark方法就加1，调用一次park就减1，多次调用unpark不会积累许可证。
    可以先调用unpark方法，后调用park方法。
8. AQS AbstractQueuedSynchronizer
    用来构建锁或者其他同步器组件的重量级基础框架及整个JUC体系的基石
    通过内置的FIFO队列来完成资源获取线程的排队工作，并且通过一个被volatile修饰的int类型变量表示持有锁的状态
    哨兵节点、头、尾、前、后指针

9. 指令重排：
    编译器在编译时进行了编译优化，导致指令重排。
    java语言规范规定JVM线程内部维持顺序化语义。即只要程序的最终结果与它顺序化情况的结果相等，
    那么指令的执行顺序可以与代码顺序不一致，此过程叫指令的重排序。
    从源码到最后执行的指令序列过程是：
    源码->编译器优化重排序->指令级并行重排序->内存系统重排序->最后执行的指令序列
10. 内存屏障：
    Memory barrier 能够让 CPU 或编译器在内存访问上有序。一个 Memory barrier 之前的内存访问操作必定先于其之后的完成。
    Memory barrier是一种CPU指令，用于控制特定条件下的重排序和内存可见性问题。Java编译器也会根据内存屏障的规则禁止重排序。
    有的处理器的重排序规则较严，无需内存屏障也能很好的工作，Java编译器会在这种情况下不放置内存屏障。
10.1 不同硬件实现内存屏障的方式不同，Java内存模型屏蔽了这种底层硬件平台的差异，由JVM来为不同的平台生成相应的机器码。
10.2 Java内存屏障主要有Load和Store两类:
    对Load Barrier来说，在读指令前插入读屏障，可以让高速缓存中的数据失效，重新从主内存加载数据
    对Store Barrier来说，在写指令之后插入写屏障，能让写入缓存的最新数据写回到主内存
10.3 Java内存屏障类型：
    LoadLoad屏障： 对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。
    StoreStore屏障： 对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。
    LoadStore屏障： 对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。
    StoreLoad屏障： 对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它的开销是四种屏障中最大的。在大多数处理器的实现中，这个屏障是个”全能型屏障”，兼具其它三种内存屏障的功能
11. 总线风暴：
    由于volatile的mesi缓存一致性协议需要不断的从主内存嗅探和cas不断循环无效交互导致总线带宽达到峰值
    解决办法：部分volatile和cas使用synchronize
12. volatile:（无原子性）
   可见性
   禁止指令重排

13. 线程中断和虚假唤醒：
像在一个参数版本中，中断和虚假唤醒是可能的，并且该方法应该始终在循环中使用：
  synchronized (obj) {
         while (<condition does not hold>)
             obj.wait();
         ... // Perform action appropriate to condition
     }
该方法只能由作为该对象的监视器的所有者的线程调用。 有关线程可以成为监视器所有者的方式的说明，请参阅notify方法。

多线程交互中的判断只用while不能用if判断 ---> 避免线程中断和虚假唤醒（两个线程只能无影响）

14. 阻塞队列：
    ArrayBlockingQueue: 由数组构成的有界阻塞队列
    LinkedBlockingQueue：由链表组成的有界（默认界限为Integer.MAX_VALUE）阻塞队列
    SynchronousQueue: 不存储元素的阻塞队列，也即单个元素的队列

15. 线程池：

// 1 池 5工作线程
ExecutorService service1 = Executors.newFixedThreadPool(5);
// 1 池 1 工作线程
ExecutorService service2 = Executors.newSingleThreadExecutor();
// 1 池 N 工作线程
ExecutorService service3 = Executors.newCachedThreadPool();



！阿里巴巴Java开发手册明确指定不允许用 Executors创建线程池，而是通过 new ThreadPoolExecutor()的方式，避免资源耗尽的风险。！



ThreadPoolExecutor(int corePoolSize,
                  int maximumPoolSize,
                  long keepAliveTime,
                  TimeUnit unit,
                  BlockingQueue<Runnable> workQueue,
                  ThreadFactory threadFactory,
                  RejectedExecutionHandler handler)

corePoolSize: 线程池中核心线程数
maximumPoolSize: 线程池中最大线程数
keepAliveTime: 多余空闲线程（非核心线程）空闲时间超过 keepAliveTime 就会被销毁，只保留核心线程
unit: 时间单位
workQueue: 任务队列，存放被提交但是还未执行的线程
threadFactory: 创建线程的工厂
handler: 拒绝策略，当队列满了，并且并且工作线程数大于 maximumPoolSize 时，拒绝请求执行线程的策略

线程池执行流程：
1）核心线程数有空闲：分配任务，否则进任务队列，任务队列满，开启救急线程，救急线程不够用（线程池满，达到maximumPoolSize），执行拒绝策略。
救急线程空闲，空闲时间超过 keepAliveTime 就会被销毁，只保留核心线程

四大拒绝策略：
AbortPolicy(默认)：直接抛出RejectedExecutionException异常
CallerRunsPolicy: 将任务回退给调用者线程，在main线程中提交给线程池就回退交给main线程来执行
DiscardPolicy: 直接抛弃新来的任务
DiscardOldestPolicy: 直接抛弃队列中最早来的任务